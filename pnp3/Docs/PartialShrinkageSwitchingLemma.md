# План формализации `partial_shrinkage_for_AC0`

В этом документе собираем контекст и пошаговый план формального доказательства аксиомы
`partial_shrinkage_for_AC0` (Switching Lemma для схем AC⁰), заменяющей текущую аксиому
в `ThirdPartyFacts/Facts_Switching.lean`.

## 1. Целевое утверждение

`partial_shrinkage_for_AC0` реализует многослойную версию switching-леммы Хёстада (1986):
для любой схемы класса AC⁰ размера ≤ `M`, глубины `d` и над `n` переменными существует
частичный сертификат shrinkage, который:

* фиксирует не более `ℓ ≤ log₂ (M + 2)` переменных;
* оставляет хвостовые решающие деревья глубины `depthBound` с оценкой
  `depthBound + ℓ ≤ (log₂ (M + 2))^(d + 1)`;
* аппроксимирует семейство булевых функций с ошибкой `ε ≤ 1 / (n + 2)`.

Эти параметры зашиты в структуру `AC0Parameters` и объект `PartialCertificate` в Lean.

## 2. Выбор доказательства

* Базируемся на классической вероятностной switching-лемме Хёстада (STOC 1986,
  журнальная версия — Theoretical Computer Science, 1987).
* Эта версия соответствует текущей формулировке аксиомы и не требует
  псевдослучайных генераторов (в отличие от работы Servedio–Tan, 2018).
* В доказательстве активно используем классические приёмы: индукцию по глубине,
  вероятностный метод, union bound и выбор хорошего ограничения через `Classical.choose`.

Рекомендуемые источники для формализации:

1. Johan Håstad, *Almost Optimal Lower Bounds for Small Depth Circuits* (STOC 1986).
2. Paul Beame, *A Switching Lemma Primer* (1994) — подробный и дружелюбный конспект.
3. Sanjeev Arora, Boaz Barak, *Computational Complexity: A Modern Approach* (гл. 6).
4. Stasys Jukna, *Boolean Function Complexity* (разд. 12.1–12.2).

## 3. Структура доказательства

0. **Замечание о параметрах `ℓ` и `depthBound`.**
   В `PartialCertificate` параметр `ℓ` контролирует **размер словаря хвостов**
   (`tails_len ≤ 2^ℓ`) и не обязан совпадать с глубиной ствола. Глубина ствола
   ограничивается `depthBound`, а целевая оценка формулируется как
   `depthBound + ℓ ≤ (log₂ (M + 2))^(d + 1)`. В дальнейшем мы будем строить
   ствол глубины ровно `ℓ` (для удобства), что гарантирует `tails_len ≤ 2^ℓ`.

1. **Вероятностные ограничения.**
   Для совместимости с общим стволом `PartialDT` фиксируем **ровно** `ℓ` осевых переменных:
   (i) выбираем множество `S ⊆ [n]` размера `ℓ` (равномерно), (ii) все переменные вне `S`
   назначаем равновероятно в `0/1`. Это распределение реализуем через `PMF` на конечном типе.
   Примечание: классические оценки для p‑biased ограничений (каждая переменная «жива» с вероятностью `p`)
   переносятся на модель «exact‑ℓ» с потерей лишь в константах; достаточно выбрать `p ≈ ℓ / n`.
   В аналитических оценках можно использовать p‑biased модель, но при сборке сертификата мы
   **не фиксируем** переменные вне `S` — они обрабатываются хвостовыми DT.

2. **Базовый случай (глубина 1).**
   Для формул DNF/CNF ограниченной ширины `w` доказываем:
   `Pr[ DTdepth(f|ρ) > t ] ≤ (#термов/клауз) * (p*t)^t`.
   Это классическая лемма Хёстада для глубины 1; формализуется индукцией по числу литералов.
   Здесь и далее используем `PMF` и неравенство объединения событий (union bound).

3. **Индукция по глубине.**
   Рассматриваем верхний слой OR/AND из подформул глубины `d - 1`. Индуктивно:
   (a) фиксируем одно и то же множество `S` (размер `ℓ`) для **всех** подформул `Fᵢ`,
   (b) показываем, что доля «плохих» назначений `α : {0,1}^S` для каждой `Fᵢ` ≤ `(p*t)^t`,
   (c) объединяем оценки по `i` (число подформул `T ≤ M`) через union bound.
   Итого: доля «плохих» `α` для верхнего OR/AND ≤ `M * (p*t)^t`,
   поэтому один и тот же выбор `S` работает одновременно для всей верхней композиции
   и всех функций семейства.

4. **Контроль параметров.**
   Выбираем явно параметры:
   `ℓ := min (Nat.log2 (M + 2)) n`, `t := (Nat.log2 (M + 2))^d`, `p := 1 / (16 * t)`.
   Тогда `Pr_bad ≤ M * (p*t)^t = M * (1/16)^t`.
   Требование `M * (1/16)^t ≤ 1/(n+2)` обеспечивает цель `ε ≤ 1/(n+2)`.
   Для малых `M`/`n` добавляем кейсы с усиленной константой (см. §«Малые случаи»).
   Глубина хвостов растёт на `t` при каждом уровне, итог: `depthBound + ℓ ≤ (log₂ (M+2))^(d+1)`.

5. **Выбор удачного ограничения.**
   После доказательства, что вероятность успеха > 0, применяем классический выбор,
   чтобы получить конкретное ограничение и построить объект `PartialCertificate`.

6. **Мост «вероятность → errU».**
   Формализуем лемму: для равномерного распределения на `α : {0,1}^S`
   `errU f (selectors f) = PMF.bad_mass f`, где «плохие» `α` — те, что нарушают
   ограничение на глубину хвоста. Эта лемма связывает расчёты `M * (p*t)^t`
   с требованием `errU f ≤ 1/(n+2)` и использует лишь дискретные `PMF`.
   Отдельно фиксируем, что так как хвостовые DT корректны **на всех завершениях**
   переменных вне `S`, то доля «плохих» `α` при равномерном распределении на `{0,1}^S`
   совпадает с долей ошибок при равномерном распределении на `{0,1}^n`.

7. **Сборка сертификата.**
   * Ствол ветвится по `S` (|S| = `ℓ`), тем самым **фиксируя** эти переменные по ходу пути;
     число листьев ствола `= 2^ℓ`, `PDT.depth trunk = ℓ`.
   * Для каждого листа (`α : {0,1}^S`) хвост – DT глубины ≤ `t`, полученный индукцией.
   * Для каждого `f ∈ F` кладём в `selectors f` **все** листья `α`, для которых хвост
     правильно вычисляет `f`; тогда `errU f` равен доле «плохих» `α` и
     `errU f ≤ M * (p*t)^t ≤ 1/(n+2)`.
   * `tails` содержит по одному хвосту на лист ствола, поэтому `tails_len ≤ 2^ℓ`
     выполняется автоматически.
   * Проверяем `selectors_sub`, `trunk_depth_le`, `err_le` по определениям.

### Малые случаи и арифметика (Lean‑гигиена)

* Выбираем `ℓ := min (Nat.log2 (M + 2)) n`, чтобы автоматически иметь `ℓ ≤ n`.
* Кейсы `M ≤ 4`, `d = 0/1`, `n < ℓ` закрыть явными конструкциями (тривиальные деревья).
* Числовые леммы: `Nat.log2_le_iff_le_two_pow`, монотонность `Nat.pow`, неотрицательность `ℚ`.
* Использовать `PMF` на конечных типах; избегать тяжёлой `MeasureTheory`.
* Вынести лемму‑шаблон на неравенство `M * (p*t)^t ≤ 1/(n+2)` при
  `t := (Nat.log2 (M + 2))^d`, `p := 1 / (16 * t)` (и усиленные константы в «малых» случаях).

## 4. Разбиение на подзадачи Lean

1. Модуль для случайных ограничений (`RandomRestriction.lean`).
2. Лемма shrinkage глубины‑1 (`Depth1_Switching.lean`): CNF/DNF с оценкой `(#термов/клауз) * (p*t)^t`.
3. Индуктивный шаг (`MultiSwitching.lean`): OR/AND‑композиции, общая ось `S`, union bound.
4. Финальная обёртка (`Facts_Switching.lean`): замена аксиомы доказанной теоремой.
5. Тесты/спецификации: обновление `Tests/TestDriver.lean` и документации.

Каждый модуль должен содержать подробные комментарии, ссылки на литературу
и проверяемые неравенства (`linarith`, `nlinarith`, `omega`).

## 5. Текущее состояние репозитория

* Аксиома объявлена в `ThirdPartyFacts/Facts_Switching.lean` и используется в SAL.
* В `archive/pnp3/ThirdPartyFacts/ConstructiveSwitching.lean` реализованы частные случаи
  (`empty`, `constant`) — полезные шаблоны для тактики и структур сертификатов.
* Других формальных доказательств switching-леммы в открытом доступе нет, так что
  это одна из первых попыток в proof assistant.

Документ служит дорожной картой и поможет согласовать дальнейшие патчи по
замене аксиомы `partial_shrinkage_for_AC0` полноценным доказательством.

### 5.1. Промежуточные формальные результаты

* ✅ `Clause.restrict_eval_mem` и `Term.restrict_eval_mem` показывают, что
  ограничение дизъюнктивных и конъюнктивных термов корректно взаимодействует с
  подкубами `Core.Subcube`.  Эти леммы станут фундаментом для описания
  случайных ограничений и оценки глубины хвостов.
* ✅ `CNF.restrict_eval_mem` и `DNF.restrict_eval_mem` распространяют тот же
  аргумент на списковые формулы: ограничение всего слоя OR/AND сохраняет
  значение на совместимых точках и аккуратно сворачивает константы.
* ✅ Леммы `Clause.restrict_pending_length_le` и `Term.restrict_pending_length_le`
  фиксируют простой, но ключевой инвариант: ветка `pending` никогда не
  увеличивает число литералов.  Это пригодится при контроле ширины формул
  после случайных ограничений.
* ⏳ Следующий шаг — перейти к вероятностным оценкам глубины после ограничений
  (Switching Lemma глубины 1) и начать связывать их с параметрами ствола
  частичного дерева решений.

### 5.2. Обратная связь и вопросы к заказчику

* На текущий момент дополнительных вопросов нет: следующие шаги достаточно
  ясны по плану выше. Если потребуется уточнение по приоритетам или границам
  задач, дам знать сразу же, чтобы не терять время.

## 6. Финальный этап: демонтаж аксиомы

Ниже фиксируем последовательность шагов, которые нужно выполнить сразу после того,
как леммы из §4 реализованы. Цель — полностью удалить оставшуюся аксиому и оставить
в дереве только доказанные факты.

1. **Сведение новой теоремы к интерфейсу SAL.**
   * В модуле `ThirdPartyFacts/Facts_Switching.lean` сформулировать новое утверждение
     `partial_shrinkage_for_AC0` как теорему и сразу предоставить доказательство
     через собранный стек лемм (модули `RandomRestriction`, `Depth1_Switching`,
     `MultiSwitching`).
   * Сохранить публичный API (имена, сигнатуры) для совместимости с существующим
     кодом SAL.

2. **Удаление старой аксиомы.**
   * Заменить `axiom partial_shrinkage_for_AC0 : ...` на `theorem ... := ...`.
   * Удалить из `AXIOMS_FINAL_LIST.md` и смежных аналитических документов запись
     об этой аксиоме (или переместить её в секцию «Сняты»).

3. **Рефакторинг зависимостей.**
   * Проследить по `rg "partial_shrinkage_for_AC0"` все места использования.
     Для каждого файла убедиться, что Lean импортирует обновлённый модуль.
   * Если где-то использовались дополнительные вспомогательные аксиомы, постараться
     заменить их свежими леммами, выводимыми из доказательства switching-леммы.

4. **Тестирование и сборка.**
   * Запустить `lake build Pnp3` и `lake test Pnp3` (или соответствующий таргет из
     репозитория), чтобы убедиться в отсутствии регрессий.
   * При необходимости обновить скрипты CI и `Tests/TestDriver.lean`, если в них
     фигурировало упоминание аксиомы.

5. **Документация и ревизия.**
   * Обновить публичные документы (`README_PUBLICATION.md`, `FORMAL_PROOF_COMPLETE.md`,
     `PROOF_DEPENDENCY_MAP.md`) в части, касающейся снятия аксиомы. Добавить ссылку
     на новый модуль с доказательством.
   * Зафиксировать изменения в `PROOF_ANALYSIS.md` и «живых» презентациях, чтобы
     внешние читатели видели, что switching-лемма больше не аксиома.

6. **Архивация и поддержка.**
   * Перенести старый файл с аксиомой в архив (если полезно) с комментариями, почему
     он больше не нужен.
   * Оставить подробные комментарии в коде и документе с описанием структуры
     доказательства, чтобы дальнейшие доработки (оптимизация констант, расширение
     параметров) было проще реализовывать.

После выполнения этих шагов репозиторий перестанет зависеть от недоказанной
switching-леммы и перейдёт на полностью формализованную версию.
